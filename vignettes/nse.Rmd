---
title: "A guide to non-standard evaluation"
author: "Hadley Wickham"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A guide to non-standard evaluation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(lazyeval)
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

This vignette documents my last thinking on doing non-standard evaluation (NSE) in R. You will find this document useful if you want to program with functions from my packages (like dplyr and ggplot2), or you want a principled way of adding NSE to your own package. Somewhat ironically, you'll actually learn relatively little about NSE itself: instead you'll learn about formulas.


There are three challenges to doing non-standard evaluation correctly in R:

* Extracting the expression and environment associated with a promise
  (i.e. turning it into an explict object that you can pass around to
  other functions)
  
* Providing a standard way to be explicit about scoping.

* A standard unquoting mechanism so it's straightforward to create a 
  function that uses non-standard evaluation.
  
Lazy eval provides tools to solve each of these 

My recommendations for how to do this have changed substantially over time. I am fairly confident they will not have to change again. This approach and accompanying tools allows you to solve a wide range of problems that you encounter in practice, and are a substantial improvment over the previous generation.

## Formulas

Formulas are most familiar from linear models, but they are a powerful and underused aspect of the R language. A formula is an S3 class built on top of the language type (somewhat more accurately known as a call), with an attribute that captures the environment in which the formula was created:

```{r}
f <- ~ x + y + z
typeof(f)
attributes(f)
```

In this sense, the formula operator is a general "quoting" operator for R - it allows you to capture the essence of a computation: both the sequence of operations and the environment in which those computations need to be carried out.

```{r}
# The first element is always ~
f[[1]]
# The second element is the call itself
f[[2]]
```

R also supports two-sided formulas like `y ~ x`. These are useful for modelling, but not so useful in general, so we'll ignore here. The most reliable way to get to this expression is with `rhs()`, short for right-hand side. This function will raise an error if the input is not a one-sided function.

```{r}
rhs(f)
```

The lazyeval package provides a number of functions to make working with formulas easier. For example, the `feval()` function evaluates the formula's expression in the formula's environment.

```{r}
f <- ~ 1 + 2 + 3
feval(f)
```

This is powerful because it allows us to separate the definition of a computation from its evaluation. This is useful because we can computation on the expression itself, or as we'll see shortly, evaluate it in a slightly non-standard way.

Because the formula captures the environment in which it was evaluated, this approach is robust:

```{r}
foo <- function(x) {
  ~ 1000 + x
}
f <- foo(10)
f
x <- 1
feval(f)
```

Because the literal values are not shown in the formula (they're looked up in the attached environment), it can be hard to see what's going on. Lazyeval provides a solution for this in the form of `funwrap()`:

```{r}
f
funwrap(f)
```

## Use formulas

> _Bob Loblaw_: ...whether or not those promises were made explicit.
>
> _Tobias_: You want me to be explicit?

We'll illustrate these ideas by implementing a version of the `subset` function from base R.  The goal of the `subset()` is to make it easy to select rows matching criteria specified from the columns. It has three advantages over `[`:

1.  If many variables are involved in the expression, you don't need to 
    repeat the name of the data frame each time, so the result is much more
    concise.

1.  It drops rows where the condition evaluates to `NA` rather filling
    them in with `NA`s
    
1.  It always returns a data frame so you don't need to remember to do
    `drop = FALSE` for single column data frames.

The base version uses non-standard evaluation which makes it a little fragile and hard to understand. Instead we'll require the user to provide a formula.

```{R}
subset <- function(df, subset) {
  rows <- feval(subset, df)
  if (!is.logical(rows)) {
    stop("`subset` must be logical.", call. = FALSE)
  }
  
  rows <- rows & !is.na(rows)
  df[rows, , drop = FALSE]
}

df <- data.frame(x = 1:5, y = 5:1)
subset(df, ~ x <= 2)
```


## Be explicit

We could wrap this behaviour up into a (somewhat) more useful function:

```{r}
threshold_x <- function(df, threshold) {
  subset(df, ~ x > threshold)
}
threshold_x(df, 3)
```

But there are two ways that this function might fail:

1.  The data frame might not have `x`. This will fail unless there's a variable called
    `x` hanging around in the global environment:
    
    ```{r, error = TRUE}
    df2 <- data.frame(y = 5:1)
    
    # Throws an error
    threshold_x(df2, 3)
    
    # Silently gives the incorrect result!
    x <- 5
    threshold_x(df2, 3)
    ```
    
1.  The data frame might have a variable called `threshold`:

    ```{r}
    df3 <- data.frame(x = 1:5, y = 5:1, threshold = 4)
    threshold_x(df3, 3)
    ```

These failures are partiuclarly pernicious because they don't give a useful error message: instead they silently give an incorrect result. Both failures arise because `feval()` looks first in the data frame and then in the environment of the formula. To make this function more reliable, we're going to have to be more explicit. `feval()` provides two pronouns to make this possible:

* `.data` is bound to the data frame.
* `.env` is bound to the environment of a function.

(They start with `.` to avoid accidentally clobbering existing objects in the environment.)

We can use these objects to prevent the `feval()` for looking in the wrong place accidently:

```{r, error = TRUE}
threshold_x <- function(df, threshold) {
  subset(df, ~ .data$x > .env$threshold)
}

threshold_x(df2, 3)
threshold_x(df3, 3)
```

## Interpolation

The `threshold_x` function not very useful because it's bound to a specific variable. It would be more powerful if we could vary the variable used as well. We can do that by taking an additional argument to specify which variable to use: there are two basic alternatives for specifying the variable.

One simple approach that works well here is to use a string, and to switch from `$` to `[[`:

```{r}
threshold <- function(df, variable, threshold) {
  stopifnot(is.character(variable), length(variable) == 1)
  
  subset(df, ~ .data[[variable]] > .env$threshold)
}
threshold(df, "x", 4)
```

This is a good solution here, but only allows us to use a variable, not an arbitrary expression (e.g. `sqrt(x)`).

A more general solution is to allow the user to supply a formula:

```{r}
threshold <- function(df, variable = ~x, threshold = 0) {
  subset(df, ~ ((rhs(variable))) > .env$threshold)
}
threshold(df, ~x, 4)
```

There are two main function that make this work:

1.   `rhs()` extracts the right-hand side of a function:

    ```{r}
    rhs(~ 1 + 2)
    rhs(~ mean(x))
    ```
    
1.  `feval()` allows you to interpolate in values if you put them inside 
    a doubled-pair of parentheses. It's easiest to see what's happening by
    using the `finterp()` function which `feval()` uses to do the
    actual interpolation.
    
    ```{r}
    finterp(~ 1 + ((1 + 1)))
    
    z <- quote(x + y)
    finterp(~ mean((z)))
    ```
  
Putting these two together gives us:
  
```{r}
variable <- ~x
finterp(~ ((rhs(variable))) > .env$threshold)
```

You typically won't call `finterp()` directly as `feval()` calls it for you, but it's useful for debugging and for seeing what's going on.

If you've been paying attention, you'll have noticed that this threshold function is slightly dangerous because the `variable` isn't explicit scoped to be inside the dataframe.  It's reasonable to argue that this is ok: `threshold()` is designed for interactive use, so generally the user will see right away if something is wrong. If, however, you want to be safer, you need to do something a little tricky. `df$((x))` isn't valid R code, so you'll need to use the _prefix_ form: `` `$`(df, ((x)))``:

```{r}
threshold <- function(df, variable = ~x, threshold = 0) {
  subset(df, ~ `$`(.data, ((rhs(variable)))) > .env$threshold)
}
threshold(df, ~x, 4)
```

This also provides another way of avoiding the ambiguity problem. For simple, values you can insert them directly into the formula:

```{r}
threshold <- function(df, variable = ~x, threshold = 0) {
  subset(df, ~ `$`(.data, ((rhs(variable)))) > ((threshold)))
}
threshold(df, ~x, 4)
```

I'm not yet sure what situations should lead you to favour one approach over the other.

## Eliminating the formulas

In some situations you might want to eliminate the formula altogether, and allow the user to type regular R expressions. Although I was once much enamoured with this approach (witness ggplot2, dplyr, ...), I now think that it should be used sparingly. The approach outlined above, using formulas, leads to much simpler code, and the explict `~` makes it clear to the user that something unusual is going on.

However, lazyeval does provide some tools that allow you to eliminate the use of the formula.  If you're going to take this approach I'd recommend still having a function that uses formulas, and give it the suffix `_`. 

```{r}
subset_ <- function(df, subset) {
  rows <- feval(subset, df)
  if (!is.logical(rows)) {
    stop("`subset` must be logical.", call. = FALSE)
  }
  
  rows <- rows & !is.na(rows)
  df[rows, , drop = FALSE]
}
```

Once you have this version you can create a NSE verison that doesn't need the explicit formula. The key is the use of `explicit_promise()` which takes an unevaluateed argument (formally called a _promise_) and turns it into a regular formula object:

```{r}
subset <- function(df, expr) {
  expr <- explicit_promise(expr)
  subset_(df, expr)
}
subset(df, x == 1)
```

It's important to have a version that works with formulas, because that function can be more easily called from other functions.

Note, however, that the problems with using `substitute()` don't apply here. `explicit_promise()` is start enough to follow a chain of promises back to the original value, so, for example, this code works fine:

```{r}
scramble <- function(df) {
  df[sample(nrow(df)), , drop = FALSE]
}
subscramble <- function(df, expr) {
  scramble(subset(df, expr))
}
subscramble(df, x < 4)
```
